{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2: Probability and Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sections present in this chapter are listed below. Feel free to navigate as you like: <br>\n",
    "\n",
    "**1. Why Probability?** <br>\n",
    "**2. Random Variables** <br>\n",
    "**3. Probability Distributions** <br>\n",
    "**4. Marginal Probability** <br>\n",
    "**5. Conditional Probability** <br>\n",
    "**6. The Chain Rule of Conditional Probabilities** <br>\n",
    "**7. Independence and Conditional Independence** <br>\n",
    "**8. Expectation, Variance and Covariance** <br>\n",
    "**9. Common Probability Distributions** <br>\n",
    "**10. Bayes' Theorem** <br>\n",
    "**11. Bayesian Networks** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Why Probability?\n",
    "\n",
    "**Probabilitas** adalah ukuran seberapa mungkin suatu peristiwa atau hasil akan terjadi, dengan asumsi atau kondisi tertentu. Probabilitas dapat dinyatakan sebagai angka antara 0 dan 1, di mana 0 berarti tidak mungkin terjadi dan 1 berarti pasti terjadi. Sebagai contoh, probabilitas mendapatkan angka enam pada pelemparan dadu yang adil adalah 1/6, atau sekitar 0,17. Probabilitas juga dapat dinyatakan sebagai persentase, pecahan, atau rasio.\n",
    "\n",
    "Meskipun Computer Scientists dan Software Engineers sebagian besar berurusan dengan entitas yang sepenuhnya deterministik, Machine Learning banyak menggunakan teori probabilitas. Alasan utamanya adalah Machine Learning harus selalu berurusan dengan kuantitas yang tidak pasti atau [stochastic](https://en.wikipedia.org/wiki/Stochastic)  \n",
    "(non-deterministic). \n",
    "\n",
    "The possible sources of uncertainty are:\n",
    "- Inherent stochasticity in the system being modelled: Sebagai contoh, membuat skenario teoretis seperti permainan kartu hipotetis di mana kita menganggap bahwa kartu benar-benar diacak menjadi urutan acak.\n",
    "\n",
    "- Incomplete observability: Ketika kita tidak dapat mengamati semua variabel yang mendorong perilaku sistem, bahkan sistem deterministik dapat menjadi stochastic, misalnya [Monty Hall Problem](https://en.wikipedia.org/wiki/Monty\\_Hall\\_problem) di mana hasil yang diberikan pilihan kontestan bersifat deterministik, tetapi dari sudut pandang kontestan, hasilnya tidak pasti.\n",
    "\n",
    "- Incomplete modelling: Ketika kita menggunakan model yang harus membuang beberapa informasi yang telah diamati, informasi yang dibuang mengarah pada ketidakpastian dalam prediksi model.\n",
    "\n",
    "There are two types of kinds of probability:\n",
    "- **Frequentist Probability**:  Teori probabilitas awalnya dikembangkan untuk menganalisis frekuensi peristiwa (yang sering dapat diulang, misalnya menarik tangan kartu tertentu dalam permainan poker). Ketika kita mengatakan bahwa suatu hasil memiliki probabilitas p untuk terjadi, itu berarti jika kita mengulangi percobaan tak terhingga kali, maka proporsi p dari pengulangan itu akan menghasilkan hasil tersebut. Jenis probabilitas ini, yang berhubungan langsung dengan tingkat terjadinya peristiwa, disebut frequentist probability.\n",
    "\n",
    "\n",
    "- **Bayesian Probability**: Penalaran di atas tampaknya tidak berlaku untuk eksperimen yang tidak dapat diulang, misalnya ketika dokter mengatakan bahwa pasien memiliki 40% kemungkinan terkena flu, probabilitas tersebut mewakili **degree of belief**, dengan angka 1 menunjukkan kepastian mutlak bahwa pasien memiliki flu dan 0 menunjukkan kepastian mutlak bahwa pasien tidak memiliki flu. Jenis probabilitas ini, yang terkait dengan tingkat penalaran kualitatif, disebut **Bayesian Probability**.\n",
    "\n",
    "Namun, untuk memenuhi sifat-sifat yang kita harapkan dari penalaran akal sehat tentang ketidakpastian, kita memperlakukan probabilitas Bayesian dan frequentist dengan cara yang persis sama. Misalnya, probabilitas bahwa seorang pemain akan memenangkan permainan poker dengan memiliki set kartu tertentu dihitung dengan cara yang sama dengan probabilitas bahwa seorang pasien memiliki penyakit tertentu dengan memiliki gejala tertentu.\n",
    "\n",
    "Lalu, **mengapa Probabilitas?**\n",
    "- Dengan bantuan probabilitas kita dapat menentukan kemungkinan kondisi di sebuah populasi hanya dengan menguji sample (sebagian kecil dari populasi)\n",
    "- Dengan probabilitas, dapat membantu kita menghindari asumsi dan menghitung probailitas yang salah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random Variables\n",
    "**Variabel acak** adalah variabel, misalnya x, yang dapat mengambil nilai-nilai (keadaan) secara acak. Karena ia mengambil nilai secara acak, maka harus ada probabilitas yang terkait dengan masing-masing nilai tersebut. Oleh karena itu, sebuah variabel acak harus dikaitkan dengan distribusi probabilitas yang menentukan seberapa mungkin masing-masing keadaan tersebut terjadi.\n",
    "\n",
    "There are two types of random variables:\n",
    "- Discrete: Nilai nya cacah ([countably infinite](https://en.wikipedia.org/wiki/Countable_set)). Contoh: \n",
    "    - Banyaknya angka yang muncul dari pelemparan 2 koin {0, 1, 2}\n",
    "    - Banyaknya kendaraan yang melintas di jalan Arief Rahman Hakim, Nilainya bisa 0, 1, 2, dan seterusnya, secara teori bisa tak terhingga tapi masih cacah\n",
    "- Continuous: Pengambilam nilai dalam suatu set interval yang tak terhitung (infinite possibilities), biasanya meliputi seluruh rentang bilangan real dalam interval tertentu Contoh:\n",
    "    - Suhu Harian di Kota Surabaya\n",
    "    - Lama Waktu Tunggu di Halte Bus\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"./images/discretexcontinuous.png\"\n",
    "    \n",
    "\n",
    "More details on these in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Probability Distributions\n",
    "\n",
    "A **probability distribution** is a description of how likely a random variable or a set of random variables is, to take on each of its possible states. For example, if the random variable x can take values $\\{1,2\\}$, then $Pr(\\text{x}= 1) = 0.4$ specifies the probability distribution of x, where the probability of x taking the value 1 is 0.4 and the probability of x taking the value 2 is 0.6. Probability distributions are described based on whether the random variable is discrete or continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Discrete Variables and Probability Mass functions\n",
    "The probability distribution over ***discrete random variables** is described using a **probability mass function** (PMF). Along with its random variable, it is denoted as: x ~ $P(\\text{x})$. \n",
    "Note that $P(x)$ denotes $P(\\text{X} = x)$, which is the probability that x = $x$. A probability mass function acting over multiple variables is called a **joint probability distribution**. $P(\\text{x} = x, \\text{y} = y)$ denotes the probability that x = $x$ and y = $y$ simultaneously. \n",
    "\n",
    "For a function $P$ to be a PMF, it must satisfy these conditions:\n",
    "\n",
    "- The [domain](https://en.wikipedia.org/wiki/Domain_of_a_function) of P must be all possible states of x.\n",
    "- Nilai PMF harus non-negatif \n",
    "    - $\\forall x \\in $ x, $ 0 \\leq P(x) \\leq 1$  \n",
    "- Penjumlahan PMF pada semua nilai variable random adalah 1\n",
    "    - $ \\sum_{x \\in \\text{x}} P(x) = 1$ (normalization)\n",
    "\n",
    "For example, the uniform distribution on a random variable x with $k$ different states is given by: \n",
    "<br> <br>\n",
    "$$ P(\\text{x} = x_i) = 1/k $$\n",
    "\n",
    "To arrive at this, let we use the normalization condition:\n",
    "\n",
    "$$ \\sum_{i = 1}^{k} P(x_i) = 1 $$\n",
    "\n",
    "In a uniform distribution, all the states have the same probability (say p). Thus, we get:\n",
    "$$ kp = 1 $$\n",
    "$$ \\Rightarrow p = 1/k $$\n",
    "\n",
    "In much more simpler terms, PMF adalah fungsi yang memetakan nilai pada variable random diskrit menjadi nilai peluang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "k = 10\n",
    "x = range(1, k+1)\n",
    "prob = [float(1)/k] * k\n",
    "plt.scatter(x, prob)\n",
    "plt.xticks(np.arange(min(x), max(x)+1, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Studi Kasus PMF\n",
    "\n",
    "- Misal, pada pelemparan 3 koin. kita ingin memetakan banyak \"Heads/H/Kepala\" yang muncul maka \n",
    "\n",
    "$$\\Omega = {HHH,HHT,HTH,THH,TTH,THT,HTT,TTT}$$\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"./images/pmf.png\" width='75%'>\n",
    "\n",
    "- Variabel acak $X$ sekarang bisa mengambil nilai $$\\{0,1,2, 3\\}$$\n",
    "    - X=0 berarti tidak ada kepala yang muncul (TTT).\n",
    "    - X=1 berarti satu kepala muncul (TTH, THT, HTT).\n",
    "    - X=2 berarti dua kepala muncul (HHT, HTH, THH).\n",
    "    - X=3 berarti semua koin menunjukkan kepala (HHH).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "n = 3  # jumlah percobaan\n",
    "p = 0.5  # probabilitas head\n",
    "\n",
    "x_values = np.arange(0, n + 1)\n",
    "probabilities = binom.pmf(x_values, n, p)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = sns.barplot(x=x_values, y=probabilities, palette=\"Blues_d\")\n",
    "plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "plt.title(\"Distribusi Probabilitas Kepala dalam Pelemparan Tiga Koin\")\n",
    "plt.xlabel(\"Jumlah Kepala\")\n",
    "plt.ylabel(\"Probabilitas\")\n",
    "plt.xticks(ticks=np.arange(len(x_values)), labels=[f\"{i} Heads\" for i in x_values])\n",
    "\n",
    "# tambah angka pada bar\n",
    "for bar, probability in zip(bars.patches, probabilities):\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        f\"{probability:.3f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Probabilitas pelemparan 3 koin tersebut bisa dinotasikan sebagai berikut\n",
    "$$P(X=0) = P(TTT) = \\frac{1}{8} = 0.125$$\n",
    "$$P(X=1) = \\frac{3}{8} = 0.375$$\n",
    "$$P(X=2) = \\frac{3}{8} = 0.375$$\n",
    "$$P(X=3) = P(HHH) = \\frac{1}{8} = 0.125$$\n",
    "\n",
    "Yang dimana hasil penjumlahan PMF pada semua nilai variable random adalah 1\n",
    "\n",
    "- $ \\sum_{x \\in \\text{x}} P(x) = 1$ (normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Continuous variables and Probability Density Functions\n",
    "We describe probability distributions using a **probability density function** (PDF) (denoted by $p$) when working with continuous random variables. $p$ must satisfy the following conditions to be a PDF:\n",
    "- The domain of $p$ should be all the possible states of x.\n",
    "- $\\forall x \\in$ x, $p(x) \\geq 0$ i.e. $p(x)$ can be greater than 1.\n",
    "- Area under curve dari $-\\infty$ hingga $\\infty$ bernilai 1\n",
    "    - $\\int_{-\\infty}^{\\infty} p(x) \\, dx = 1$\n",
    "\n",
    "It's important to understand here that $p(x)$ doesn't give the probability of a specific state. The probability of landing inside an infinitesimal region with volume $\\delta x$ is given by $p(x)\\delta x$. Thus, the probability that $x$ lies in the interval $[a,b]$ is given by: $\\int_{[a,b]} p(x)dx$. The diagram below better illustrates this.\n",
    "![pdf](http://slideplayer.com/slide/8387312/26/images/12/The+Probability+Density+Function.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam hal ini, PDF membantu menghitung peluang dimana nilai X berada pada interval misal a hingga b, yang dinotasikan sebagai\n",
    "\n",
    "$$ P(a \\leq X \\leq b) = \\int_{a}^{b} f(x) \\, dx$$\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"./images/pdf.png\" width='75%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, consider a uniform distribution on an interval of real numbers. This is denoted by: $ x \\sim U(a, b) $ <br>\n",
    "The corresponding function $u(x; a,b)$ (\";\" denoting \"parameterized by\") is given by:\n",
    "\n",
    "$$ \n",
    "\\\\ \n",
    "u(x; a,b) = \n",
    "     \\begin{cases}\n",
    "       \\frac{1}{b-a} &\\quad \\text{for } x \\in [a, b]\\\\\n",
    "       0 &\\quad otherwise\n",
    "     \\end{cases}\n",
    "\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "a = 2\n",
    "b = 4\n",
    "\n",
    "value = float(2) / 4\n",
    "x = [a, b]\n",
    "y = [value, value]\n",
    "plt.plot(x, y)\n",
    "plt.xticks(range(10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Studi Kasus PDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mu = 10  # rata-rata tinggi pohon\n",
    "sigma = 2  # standar deviasi tinggi pohon\n",
    "\n",
    "# Batas bawah dan atas\n",
    "lower_bound = 9\n",
    "upper_bound = 12\n",
    "\n",
    "# Menghitung CDF untuk batas bawah dan atas\n",
    "cdf_lower = norm.cdf(lower_bound, mu, sigma)\n",
    "cdf_upper = norm.cdf(upper_bound, mu, sigma)\n",
    "\n",
    "# Probabilitas adalah area di antara dua batas ini\n",
    "probability = cdf_upper - cdf_lower\n",
    "\n",
    "print(f\"Probabilitas tinggi pohon antara 9 dan 12 meter adalah: {probability:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(mu - 3 * sigma, mu + 3 * sigma, 1000)\n",
    "# Menghitung nilai PDF untuk setiap x\n",
    "pdf = norm.pdf(x, mu, sigma)\n",
    "\n",
    "# Menghitung area di bawah kurva\n",
    "plt.fill_between(\n",
    "    x, pdf, where=(lower_bound <= x) & (x <= upper_bound), color=\"skyblue\", alpha=0.5\n",
    ")\n",
    "\n",
    "plt.plot(x, pdf, \"r-\", lw=2)\n",
    "\n",
    "plt.axvline(lower_bound, color=\"grey\", linestyle=\"--\")\n",
    "plt.axvline(upper_bound, color=\"grey\", linestyle=\"--\")\n",
    "\n",
    "plt.title(\"Distribusi Normal Tinggi Pohon dengan Area Antara 9 dan 12 Meter\")\n",
    "plt.xlabel(\"Tinggi Pohon (meter)\")\n",
    "plt.ylabel(\"PDF\")\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = 6\n",
    "\n",
    "# Menghitung CDF untuk batas bawah\n",
    "cdf_lower = norm.cdf(lower_bound, mu, sigma)\n",
    "\n",
    "# Peluang tinggi pohon lebih dari 6 meter adalah kebalikan dari CDF pada 6 meter\n",
    "probability_above_6 = 1 - cdf_lower\n",
    "\n",
    "print(f\"Peluang tinggi pohon lebih dari 6 meter adalah: {probability_above_6:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "x = np.linspace(mu - 4 * sigma, mu + 4 * sigma, 1000)\n",
    "y = norm.pdf(x, mu, sigma)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x, y, \"r-\", lw=2)\n",
    "ax.fill_between(x, 0, y, where=(x > lower_bound), color=\"skyblue\", alpha=0.5)\n",
    "\n",
    "ax.set_title(\"Distribusi Probabilitas Tinggi Pohon\")\n",
    "ax.set_xlabel(\"Tinggi Pohon (meter)\")\n",
    "ax.set_ylabel(\"Probabilitas\")\n",
    "\n",
    "# Mark the lower bound\n",
    "ax.axvline(x=lower_bound, color=\"grey\", linestyle=\"--\")\n",
    "ax.annotate(\n",
    "    f\"{lower_bound}m\",\n",
    "    xy=(lower_bound, 0),\n",
    "    xytext=(lower_bound, np.max(y) / 2),\n",
    "    arrowprops=dict(facecolor=\"black\", shrink=0.05),\n",
    "    horizontalalignment=\"right\",\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "probability_above_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Marginal Probability\n",
    "\n",
    "Sometimes we know the probability distribution over a set of variables and need to find the probability over just a subset of them. The probability over the subset is called **marginal probability distribution**.\n",
    "\n",
    "For example, if we know $P(\\text{x}, \\text{y})$, we can find $P(\\text{x})$ as:\n",
    "$$ \\forall x \\in \\text{x}, P(\\text{x} = x) = \\sum_{y} P(\\text{x} = x, \\text{y} = y)$$\n",
    "\n",
    "This image better illustrates how we calculate marginal probabilities: <br> <br>\n",
    "<img src=\"https://dlsun.github.io/probability/bookdown-demo_files/figure-html/marginal-x-1.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  Conditional Probability\n",
    "\n",
    "This is one of the most important concept in probability theory. Sometimes we are interested in calculating the probability of some event (X) , \"conditioned\" on the knowledge that another event (Y) has happened. It is denoted by $P(X \\hspace{.1cm}| \\hspace{.1cm} Y)$. For example, at the beginning of a class, the probability that a student will score well on a subject is the same for all the students. But if we are given that a particular student does well on most of his subjects, then the probability that the student will score well, given that the student scores well on most of his subjects, increases. It can be computed by the formula:\n",
    "\n",
    "$$ P(\\text{y} = y \\hspace{.1cm}| \\hspace{.1cm} \\text{x} = x) = \\frac{P(\\text{y} = y , \\text{x} = x)}{P(\\text{x} = x)} $$\n",
    "\n",
    "The conditional probability is defined only when $P(\\text{x} = x) > 0$ as we can't condition on an event that never occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. The Chain Rule of Conditional Probabilities\n",
    "\n",
    "Any joint probability distribution over many random variables may be decomposed into conditional distributions over only one variable. Let's take a simple example before we look at the general expression. From the definition of conditional probability, we have: $ P(\\text{b}, \\text{c}) = P(\\text{b} \\hspace{.1cm} | \\hspace{.1cm} \\text{c}) P(\\text{c}) $. <br>\n",
    "We want to decompose $P(\\text{a}, \\text{b}, \\text{c})$. Applying the formula for conditional probability to $P(\\text{a}, \\text{b}, \\text{c})$, we get:\n",
    "\n",
    "$$ P(\\text{a}, \\text{b}, \\text{c}) = P(\\text{a} \\hspace{.1cm} | \\hspace{.1cm} \\text{b}, \\text{c})P(\\text{b}, \\text{c}) $$\n",
    "$$\\Rightarrow P(\\text{a}, \\text{b}, \\text{c}) = P(\\text{a} \\hspace{.1cm} | \\hspace{.1cm} \\text{b}, \\text{c})P(\\text{b} \\hspace{.1cm} | \\hspace{.1cm} \\text{c}) P(\\text{c})\n",
    "$$\n",
    "\n",
    "The general expression is given by:\n",
    "$$P(\\text{x}^{(1)}, ..., \\text{x}^{(n)}) = P(\\text{x}^{(1)}) \\prod_{i=2}^{n} P(\\text{x}^{(i)} \\hspace{.1cm} | \\hspace{.1cm} \\text{x}^{(1)},..., \\text{x}^{(i-1)}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Independence and Conditional Independence\n",
    "Two random variables x & y are said to be **independent** (x $\\perp$ y) if they satisfy: <br> <br>\n",
    "$$ \\forall x \\in \\text{x}, y \\in \\text{y}, P(\\text{x} = x, \\text{y} = y) = P(\\text{x} = x)P(\\text{y} = y) $$\n",
    "\n",
    "Using the definition of conditional probability, this implies: <br> <br>\n",
    "$$ P(\\text{x} = x, \\text{y} = y) = P(\\text{x} = x \\hspace{.1cm} | \\hspace{.1cm}  \\text{y} = y)P(\\text{y} = y)=  P(\\text{x} = x)P(\\text{y} = y)$$\n",
    "$$ \\Rightarrow P(\\text{x} = x \\hspace{.1cm} | \\hspace{.1cm}  \\text{y} = y)=  P(\\text{x} = x)$$\n",
    "<br>\n",
    "Similarly, $P(\\text{y} = y \\hspace{.1cm} | \\hspace{.1cm}  \\text{x} = x)=  P(\\text{y} = y) $. However, this scenario rarely occurs. The more commonly observed phenomenun is that of **conditional independence**. Two random variables x & y are said to be conditional independent (x $\\perp$ y | z) given a random variable z if: <br> <br>\n",
    "\n",
    "$$ \\forall x \\in \\text{x}, y \\in \\text{y}, \\forall z \\in \\text{z}, P(\\text{x} = x, \\text{y} = y \\hspace{.1cm} | \\hspace{.1cm}  \\text{z} = z) = P(\\text{x} = x \\hspace{.1cm} | \\hspace{.1cm} \\text{z} = z)P(\\text{y} = y \\hspace{.1cm} | \\hspace{.1cm} \\text{z} = z) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Expectation, Variance and Covariance\n",
    "\n",
    "#### A. Expectation\n",
    "The **expectation**, or **expected value**, of some function $f(x)$ with respect to a probability distribution $P(x)$ is the average, or mean value, that the function $f$ takes on, when $x$ is drawn from $P$. For discrete variables this can be computed with a summation: <br> <br>\n",
    "$$ \\mathbb{E}_{x \\sim P}[f(x)] = \\sum_{x} P(x)f(x) $$ \n",
    "\n",
    "For continuous variables, it is computed with an integral:\n",
    "$$ \\mathbb{E}_{x \\sim p}[f(x)] = \\int p(x)f(x) $$\n",
    "\n",
    "The expectation of $f(x)$ is simply represented as $\\mathbb{E}[f(x)]$. Expectations are linear: <br> <br>\n",
    "$$ \\mathbb{E}_{x}[\\alpha f(x) + \\beta g(x)] = \\alpha \\mathbb{E}_{x}[f(x)] + \\beta \\mathbb{E}_{x}[g(x)]$$\n",
    "\n",
    "In much more simpler terms, Expectation adalah nilai-rata-rata yang mungkin muncul dari kejadian yang banyak/berulang-ulang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Variance\n",
    "\n",
    "Jika terdapat data yang memiliki nilai yang beragam, bagaimana cara mendeskripsikan persebaran data tersebut? jawaban nya adalah **Variance**. It gives a measure of how much the values of random variable x vary/tersebar (denoted by $\\sigma$). \n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"./images/variance_2.png\" width='75%'>\n",
    "\n",
    "Terdapat permisalan, nilai ujian fisika 15 orang = [7,8,8,7,8,9,7,8,9,7,7,7,8,9,7], lalu bagaimana cara mendeskripsikan persebaran data tsb melalui sebuah **angka?**\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"./images/variance_0.png\" width='75%'>\n",
    "\n",
    "Bagaimana cara mengukur persebaran tersebut?\n",
    "- memakai **jarak**\n",
    "- jarak dari referensi ke suatu titik $ d = (x - \\mu) $\n",
    "- Namun dalam kasus ini, ktia memiliki lebih dari satu nilai ujian (7, 8, 9) sehingga akan lebih baik jika digunakan rata-rata dari jarak $$\\hat{d} = \\frac{\\sum_{i} (x_i - \\mu)}{n}$$\n",
    "- Permasalahan muncul ketika nilai $ x < \\mu (rata-rata) $, misal $ x - 7 $\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"./images/variance_1.png\" width='75%'>\n",
    "\n",
    "- Solusi = diberi kuadrat, sehingga rumus variance bisa dinotasikan sebagia berikut $$ \\sigma^2 = \\frac{\\sum_{i} (x_i - \\mu)^2}{n} $$\n",
    "\n",
    "atau juga bisa disederhanakan* menjadi\n",
    "$$ Var(f(x)) = \\mathbb{E}[(f(x) - \\mathbb{E}[f(x)])^2] $$\n",
    "\n",
    "\n",
    "The image below shows how the probability distribution of a Gaussian (explained later) varies with the variance. Lower the variance, more peakier the distribution. \n",
    "<img src=\"https://images.deepai.org/glossary-terms/variance-2917933.jpg\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "The square root of variance is called **standard deviation**. Hal ini berguna untuk mengukur \"persebaran\" data, Yang dinotasikan sebagai berikut \n",
    "$$ \\sigma = \\sqrt{\\text{var}(X)} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Covariance\n",
    "\n",
    "Pada section sebelumnya, variance digunakan untuk mengukur bagaimana data bervariasi dalam 1 variable? contohnya persebaran data tinggi badan siswa, lalu bagaimana jika kita menambahkan 1 variable lagi yakni berat badan siswa? bagaimana persebaran data nya? \n",
    "\n",
    "Dalam hal ini, **Convariance** bisa mengetahui bagaimana persebaran data tinggi badan dan berat badan secara bersamaan. Alias, covariance adalah persebaran data dari 2 variable.\n",
    "\n",
    "- Kovarians dapat dicari dengan menghitung:\n",
    "$$ \\ Cov(x,y)=\\frac{\\sum_{i=1}^{n}(x_{i}-\\mu _{x})(y_{i}-\\mu _{y})}{n-1} $$\n",
    "\n",
    "atau dengan notasi lain\n",
    "<br>\n",
    "$$ Cov(f(x), g(y)) = \\mathbb{E}[(f(x) - \\mathbb{E}[f(x)])(g(y) - \\mathbb{E}[g(y)])] $$\n",
    "\n",
    "Nilai kovarians dapat memberikan informasi tentang arah perubahan kedua variabel tersebut.\n",
    "- Jika nilai kovarians **positif**, hal ini mengindikasikan bahwa variabel independen dan variabel dependen cenderung berubah ke arah yang sama. Dengan kata lain, ketika nilai variabel independen meningkat, nilai variabel dependen juga cenderung meningkat. juga sebaliknya ketika menurun\n",
    "- Jika nilai kovarians **negatif**, hal ini menunjukkan bahwa variabel independen dan variabel dependen cenderung berubah ke arah yang berlawanan. Artinya, ketika nilai variabel independen meningkat, nilai variabel dependen cenderung menurun, dan sebaliknya.\n",
    "- Jika nilai kovarians **mendekati nol**, dapat disimpulkan bahwa kedua variabel tersebut relatif tidak berhubungan atau memiliki korelasi yang lemah. Dalam situasi ini, perubahan nilai pada satu variabel tidak terlalu mempengaruhi perubahan nilai pada variabel lainnya.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"./images/covariance.png\" width='75%'>\n",
    "\n",
    "Covariance and independence and related but distinct concepts. Independence implies zero covariance, but zero covariance doesn't necessarily imply independence. Hence, independence is a stronger condition. \n",
    "\n",
    "**Covariance matrix** of a random vector $\\boldsymbol{x} \\in \\mathbb{R} ^{n}$ is an $n$ x $n$ matrix denoted by $\\Sigma$, such that:\n",
    "$$ Cov(x)_{i, j} = Cov(x_i, x_j), i \\neq j$$\n",
    "$$ Cov(x)_{i, i} = Var(x_i)$$\n",
    "\n",
    "Terdapat 2 jenis matrix, yaitu 2D and 3 Dimensional convarianve matrix\n",
    "<p align=\"center\">\n",
    "    <img src=\"./images/covariance-2.png\" width='75%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Studi Kasus\n",
    "Hubungan Biaya Periklanan dengan Tingkat Penjualan\n",
    "\n",
    "Diketahui data suatu penelitian terhadap hubungan antara biaya periklanan dengan tingkat penjualan sebagai berikut: (dalam ribuan rupiah)\n",
    "\n",
    "<center>\n",
    "\n",
    "|Biaya Periklanan|Tingkat Penjualan|\n",
    "|:-:|:-:|\n",
    "|70|30|\n",
    "|71|36|\n",
    "|72|44|\n",
    "|73|46|\n",
    "|74|50|\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Biaya Periklanan\": [70, 71, 72, 73, 74],\n",
    "        \"Tingkat Penjualan\": [30, 36, 44, 46, 50],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Plott 'Biaya Periklanan' in blue\n",
    "plt.scatter(df.index, df[\"Biaya Periklanan\"], color=\"blue\", label=\"Biaya Periklanan\")\n",
    "\n",
    "# Plot'Tingkat Penjualan' in orange\n",
    "plt.scatter(\n",
    "    df.index, df[\"Tingkat Penjualan\"], color=\"orange\", label=\"Tingkat Penjualan\"\n",
    ")\n",
    "\n",
    "plt.title(\"Scatter Plot Persebaran Variance\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Nilai\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terlihat, Tingkat Penjualan lebih tersebar dibandingkan dengan nilai pada Biaya Periklanan. Dengan demikian varians Tingkat Penjualan lebih besar dibandingkan dengan Biaya Periklanan. Perhitungan Varians bisa dilakukan dengan bantuan library numpy yang diimport dengan (import numpy as np) sebagai berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.var(df[[\"Biaya Periklanan\", \"Tingkat Penjualan\"]], ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begitu juga dengan perhitungan covariance, numpy memiliki fungsi .cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(df[\"Biaya Periklanan\"], df[\"Tingkat Penjualan\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari covariance matrix tersebut, didapatkan kovarian 12.5, sehingga bisa disimpulkan bahwa data biaya periklan dan data tingkat penjualan saling berhubungan. Namun dengan kovarians tidak mudah ditafsirkan secara kualitatif, sehingga kita perlu menghitung korelasi.\n",
    "\n",
    "**Correlation** digunakan untuk mengukur kekuatan dan arah hubungan linear antara 2 variable random.  Dengan library pandas kita dapat menggunakan fungsi corr() untuk menghitung korelasi antara Biaya Periklanan dan Tingkat Penjualan sebagai berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Biaya Periklanan\", \"Tingkat Penjualan\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nilai diagonal 1 menunjukkan korelasi setiap kolom dengan dirinya sendiri. Nilai 0.97 merupakan koefisien korelasi Pearson antara Biaya Periklanan dan Tingkat Penjualan. Sehingga dari hasil perhitungan tersebut kita dapatkan korelasi sebesar 0.97, artinya korelasi positif. Korelasi positif menunjukkan bahwa kenaikan satu variabel menyebabkan penambahan nilai pada variabel lainnya. Agar lebih jelas maka akan dibuat visualisasi sebagai berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "\n",
    "# dengan bantuan library seaborn (import searborn as sns)\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar_kws={\"shrink\": 0.5})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Common Probability Distributions\n",
    "\n",
    "#### 9.1 Bernoulli Distribution\n",
    "The Bernoulli distribution is a distribution over a single binary random variable. It is controlled by a single parameter $\\phi \\in [0,1]$, which gives the probability of the random variable being equal to 1. For e.g., in the event of tossing a coin, $p$ represents the probability that a heads shows up (Assuming heads is represented by 1). <br>\n",
    "**Properties**:\n",
    "- $P (x = 1) = \\phi $ <br>\n",
    "- $P (x = 0) = 1 − φ$ <br>\n",
    "- $P (\\text{x} = x) = \\phi^x(1 − \\phi)^{1−x}$ <br>\n",
    "- $E_x[x] = \\phi$ <br>\n",
    "- $Var_x(x) = \\phi(1 − \\phi)$ \n",
    "\n",
    "#### 9.2 Multinoulli Distribution\n",
    "The Multinoulli distribution is similar to the Bernoulli distribution, with the difference being that the discrete random variable can have k different states. It is parameterized by a vector $\\boldsymbol{p} \\in [0,1] ^{k-1}$, where $p_i$ indicates the probability of the $i^{th}$ state. The final $k^{th}$ state is given by $(1 - \\boldsymbol{1}^T \\boldsymbol{p})$ where $\\boldsymbol{1}^T \\boldsymbol{p} \\leq 1$.  <br>\n",
    "\n",
    "#### 9.3 Gaussian Distribution \n",
    "\n",
    "The most widely used distribution over real numbers is the **normal** or **gaussian distribution**: <br> <br>\n",
    "$$ \\mathcal{N}(x; \\mu, \\sigma) = \\sqrt{\\frac{1}{2 \\pi \\sigma^2}} exp(-\\frac{1}{2\\sigma^2}(x-\\mu)^2)$$\n",
    "\n",
    "where $\\mu$ is the mean (or peak value) of the distribution and $\\sigma^2$ denotes the variance. Feel free to play around with the values of *variance* and *mu* in the snippet below to see how the parameters effect the distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"./images/gaussian.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "mu = 0.0  # mean of the distribution\n",
    "variance = 1  # variance of the distribution\n",
    "sigma = np.sqrt(variance)  # standard deviation\n",
    "\n",
    "x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
    "\n",
    "pdf = norm.pdf(x, mu, sigma)\n",
    "\n",
    "plt.plot(x, pdf)\n",
    "plt.title('Distribusi Normal')\n",
    "plt.xlabel('Nilai')\n",
    "plt.ylabel('Probabilitas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the absence of any prior knowledge about the distribution, the normal distribution is a good choice, owing to the **central limit theorem** (which states that the sum of many indepedent random variables is approximately normally distributed) and the fact that the normal distribution encodes the most uncertainty over the real numbers among all other probability distributions with the same variance.\n",
    "\n",
    "Generalizing to $\\mathbb{R}^n$, the mean $\\boldsymbol{\\mu}$ becomes a vector and the variance is replaced by the covariance matrix $\\boldsymbol{\\Sigma}$, which is often fixed to be a diagonal matrix. \n",
    "![normal multivariate](https://i.stack.imgur.com/EOyQI.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.4 Exponential and Laplace distributions\n",
    "\n",
    "To place a sharp peak at x = 0, we can use the **exponential distribution**:\n",
    "$$ p(x; \\lambda) = \\lambda \\hspace{.05cm} exp(-\\lambda x), \\forall x \\geq 0$$\n",
    "\n",
    "Thus, the probability for $x < 0$ is 0. A similar function that allows to place a peak at x = $\\mu$ is the **Laplace distribution**: <br> <br>\n",
    "$$p(x; \\mu, \\gamma) = \\frac{1}{2 \\gamma} \\hspace{.05cm} exp(-\\frac{|x-\\mu|}{\\gamma})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.5 The Dirac Distribution and Empirical Distribution\n",
    "\n",
    "The Dirac delta function is defined such that it is zero everywhere except 0, where its value is 1.\n",
    "$$ \n",
    "\\\\ \n",
    "\\delta(x) = \n",
    "     \\begin{cases}\n",
    "       1 &\\quad x = 0\\\\\n",
    "       0 &\\quad otherwise\n",
    "     \\end{cases}\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "It can be visualized as a gaussian distribution with mean and variance as 0. \n",
    "![dirac delta](http://www.chebfun.org/examples/complex/img/Hyperfuns_01.png)\n",
    "\n",
    "Suppose we want to define a probability distribution with all the masss centered on one value (say $\\mu$), we can define $p(x)$ as:\n",
    "$$ p(x) = \\delta (x-\\mu)$$\n",
    "\n",
    "A common use of the Dirac delta distribution is as a component of an **empirical distribution**:\n",
    "$$ \\hat{p}(\\boldsymbol{x}) = \\frac{1}{m}\\sum_{i=1}^{m} \\delta(\\boldsymbol{x} - \\boldsymbol{x}^{(i)}) $$\n",
    "\n",
    "This assigns a probability mass of 1/m to each of the m points $\\boldsymbol{x}^{(i)}, i=1, 2, ... m$. This is because putting $\\boldsymbol{x} = \\boldsymbol{x}^{(i)}$ in the above equation will result in only one non-zero term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  9.6 Mixtures of distributions\n",
    "\n",
    "We can define probability distributions by combining other simpler probability distributions. One such way is to construct a **mixture distribution**. On each trial, the choice of which component distribution should generate the sample is determined by sampling a component identity from a multinoulli distribution:\n",
    "\n",
    "$$ P(x) = \\sum_{i} P(c = i) P (x \\hspace{.1cm} | \\hspace{.1cm} c = i) $$\n",
    "\n",
    "where $P (c)$ is the multinoulli distribution over component identities. An important concept introduced here is that of a **latent variable**, which is a random variable that we cannot observe directly. In the given case, $c$ is a latent variable. The distribution $P (x \\hspace{.1cm} | \\hspace{.1cm} c = i) $, relating the latent variable to the visible variable, determines the shape of the distribution $P(x)$, even thoughit is possible to describe $P(x)$ without reference to the latent variable.\n",
    "\n",
    "A very powerful type of mixture model is the **Gaussian Mixture model (GMM)**, where each of the component distributions is a gaussian, with a **prior probability** associated with each gaussian. The word “prior” indicates that it expresses the model’s beliefs about $c$ *before* it has observed $x$. <br>\n",
    "$P(c \\hspace{.1cm} | \\hspace{.1cm} x)$ is a **posterior probability**, because it is computed *after* observation of x. A Gaussian mixture model is a **universal approximator** of densities, in the sense that any smooth density can be approximated with any speciﬁc non-zero amount of error by a Gaussian mixture model with enough components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Bayes' Theorem\n",
    "\n",
    "A lot of times, we actually have $P(y \\hspace{.1cm} | \\hspace{.1cm} x)$ and we need to find $P(x \\hspace{.1cm} | \\hspace{.1cm} y)$. **Bayes' Rule** helps us to compute that quantity:\n",
    "\n",
    "$$ P(x \\hspace{.1cm} | \\hspace{.1cm} y) = \\frac{P(x)P(y \\hspace{.1cm} | \\hspace{.1cm} x)}{P(y)} $$\n",
    "\n",
    "where $P(y) = \\sum_x P(x)P(y \\hspace{.1cm}  | \\hspace{.1cm} x)$. Bayes' Rule is one of most important concepts in probability theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Bayesian Networks\n",
    "\n",
    "A Bayesian network is a probabilistic graphical model which represents a set of variables and their conditional dependencies using a directed acyclic graph. Bayesian Network can be used to many cases such as follows.\n",
    "\n",
    "<ul>\n",
    "    <li>Represent the relationship between multiple events</li>\n",
    "    <li>Prediction</li>\n",
    "    <li>Anomaly detection</li>\n",
    "    <li>Time series prediction</li>\n",
    "    <li>etc.</li>\n",
    "</ul>\n",
    "\n",
    "Bayesian Network consist of TWO part\n",
    "<ul>\n",
    "    <li>Direct Acyclic Graph (DAG)</li>\n",
    "    <li>Table of Conditional Probability </li>\n",
    "</ul>\n",
    "<img src=\".\\images\\dag1.png\"></img>\n",
    "<ul>\n",
    "    <li> <b>Node</b> represents the random variables</li>\n",
    "    <li> <b>Arc</b> represent the conditional probabilities between random variables </li>\n",
    "</ul>\n",
    "\n",
    "Let $x_1$, $x_2$, $x_3$, ..., $x_n$ as variables, then the probabilities of a different combination of $x_1$, $x_2$, $x_3$, ..., $x_n$ is called <b>Joint Probability Distribution.\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "$$\n",
    "P(X_i | X_{i-1}, \\ldots, X_1) = P(X_i | \\text{Parents}(X_i))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "- https://towardsdatascience.com/5-things-you-should-know-about-covariance-26b12a0516f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
